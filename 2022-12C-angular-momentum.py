# -*- coding: utf-8 -*-
"""2022-12C-angular-momentum.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-artvO6EcF1vwhsbns6FgznAqkA7pZS3
"""

# -*- coding: utf-8 -*-
"""12C-Angular-momentum-log-[20220323]-wo-3body-prof-park-ver1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xwKeCL0n40-10tki86knOmWowfNK9I0v
"""

import tensorflow as tf
import numpy
import math
import logging

from matplotlib import pyplot as plt
from mpl_toolkits import mplot3d
# %matplotlib inline
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import matplotlib.ticker as mticker
from IPython.display import display, clear_output
from sympy import Integral, Symbol

logger = logging.getLogger()
DEFAULT_TENSOR_TYPE = tf.float32
DEFAULT_TENSOR_TYPE2 = tf.float64

# wave function puff constant
N_WALKERS = 500
N_OBSERVATIONS = 30

# natural unit
hbar = 1.0
c = 1.0
epsilon0 = 1.0
fm = 1.0
fm_inverse = 1/fm
hbarc = 1.0 #197.3269804 * Mev * fm 이므로 아래 값들 정의 가능
MeV = 1/197.327
GeV = 1000.0*MeV
alpha = 1./137.036

# nucleon mass
m = []
alphamass = 3727.379
for amass in range (6):
  m.append(alphamass)

import numpy
import tensorflow as tf


class NeuralWavefunction(tf.keras.models.Model):

    def __init__(self, ndim : int, 
                 initial_containment1 : float = -0.1,
                 initial_containment2 : float = -0.1):
      
        tf.keras.models.Model.__init__(self)
        self.ndim = ndim

        self.layer1 = tf.keras.layers.Dense(32, use_bias=False)
        self.layer2 = tf.keras.layers.Dense(32, use_bias=False)
        self.layer3 = tf.keras.layers.Dense(1, use_bias=False)

        self.containment1 = tf.Variable(initial_containment1, trainable = True)
        self.containment2 = tf.Variable(initial_containment2, trainable = True)
        self.MeV = MeV

    @tf.function
    def call(self, inputs):

        input_rvec = []
        part = inputs.shape[1]
        mr = 0
        sum_m = 0
        risac = 0
        reshape000 = tf.zeros((1,1,1))

        for i in range(part):
          inputsi = tf.split(inputs, part, axis=(1))[i]
          rvec = tf.reduce_sum(inputsi, axis=(1))# x1+y1+z1,  x2+y2+z2 ... 중 하나
          mr = mr + (m[i]*self.MeV * rvec)
          sum_m = sum_m + m[i]*self.MeV

        Rvec_cmw = (mr/sum_m) #R = mr1+mr2+../M
        Rvec2_cm = tf.reduce_sum(Rvec_cmw**2, axis=(1)) # R1^2+R2^2+...

        for i in range(part):
          inputsi = tf.split(inputs, part, axis=(1))[i]
          rvec = tf.reduce_sum(inputsi, axis=(1))# x+y+z
          delr = rvec - Rvec_cmw # r1-R1, r2-R2, r3-R3,... 중 하나

          inputs_rvec = delr + reshape000
          inputs_rvec = tf.reshape(inputs_rvec ,(500,1,-1))
          input_rvec.append(inputs_rvec)

          delrbd = tf.sqrt(tf.reduce_sum(delr**2, axis=(1)))
          risac = risac + delrbd

        Rboundary2_condition = -tf.exp(self.containment1) * Rvec2_cm  #e^(aR²)
        Rboundary2_condition = tf.reshape(Rboundary2_condition, [-1,1])

        rRboundary_condition = -tf.exp(self.containment2) * risac #e^(a|R-r|)
        rRboundary_condition = tf.reshape(rRboundary_condition, [-1,1])

### before 20220907 ###############################################################        
        # input_rvec = tf.concat(input_rvec, axis=(1))
        # input = tf.reshape(input_rvec, [500, -1])
        # x = self.layer1(input)
        # x = tf.keras.activations.softplus(x)

        # x = self.layer2(x)
        # x = tf.keras.activations.softplus(x)

        # x = self.layer3(x)
        # #x = tf.keras.activations.tanh(x)        
        # return x + rRboundary_condition + Rboundary2_condition, tf.exp(x + rRboundary_condition + Rboundary2_condition)
      
### 20220915 symmetrization of bosonic particle ###################################
### 20221015 but it has mistake! It can describe the all of cases
### psi(1,2) = (psi(1,2) + psi(2,1) ) / 2.0
        # input_rvec_array = []
        # for i in range(part):
        #   input_rvec_array.append(input_rvec)


        # x_total = []
        # if part > 1:
        #   for i in range(part-1):
        #     walkero = tf.split(inputs, part, axis=(1))[i]
        #     for j in range(i+1, part):
        #       input_rvec1 = input_rvec_array[i]
        #       input_rvec2 = input_rvec_array[j]

        #       input_rvec = (input_rvec1)
        #       input_rvec = tf.concat(input_rvec, axis=(1))
        #       input = tf.reshape(input_rvec, [500, -1])

        #       x1 = self.layer1(input)
        #       x1 = tf.keras.activations.softplus(x1)

        #       x1 = self.layer2(x1)
        #       x1 = tf.keras.activations.softplus(x1)

        #       x1 = self.layer3(x1)

        #       print('input print1', input_rvec)
        #       input_rvec = (input_rvec2)
        #       input_rvec[0] = input_rvec2[1]
        #       input_rvec[1] = input_rvec2[0]
        #       # input_rvec.append(input_rvec2[1])
        #       # input_rvec.append(input_rvec2[0])


        #       print('input print0', input_rvec)

        #       input_rvec = tf.concat(input_rvec, axis=(1))
        #       print('input print2', input_rvec)        
        #       input = tf.reshape(input_rvec, [500, -1])
        #       print('input print3', input)


        #       x2 = self.layer1(input)
        #       x2 = tf.keras.activations.softplus(x2)

        #       x2 = self.layer2(x2)
        #       x2 = tf.keras.activations.softplus(x2)

        #       x2 = self.layer3(x2)
        #       x_total.append(x1)
        #       x_total.append(x2)
        # x = 0.0
        # for i in range(len(x_total)):
        #   x = x + x_total[i]
        # x = x / math.factorial(part)
            
        # return x + rRboundary_condition + Rboundary2_condition, tf.exp(x + rRboundary_condition + Rboundary2_condition)

### 20221015 Soonchul I try to fix above problem #################################
        # input_rvec_array = []
        # for i in range(part):
        #   input_rvec_array.append(input_rvec)

        # 여기에 input_rvec에는 (500,1,3) (500,1,3) (500,1,3) 이렇게 있는것 !
        x_total = []
        # number of case start ###################################################
        input_temp = []
        input_temp.append(input_rvec[0])
        input_temp.append(input_rvec[1])
        input_temp.append(input_rvec[2])

        input_rvect = tf.concat(input_temp, axis=(1)) # 같은 차원끼리 합쳐 쌓기 [[r1_x1, r1_y1, r1_z1,  r2_x1, r2_y1, r2_z1,  r3_x1, r3_y1, r3_z1],..[]..]
        input = tf.reshape(input_rvect, [500, -1])
        xt = self.layer1(input)
        xt = tf.keras.activations.softplus(xt)

        xt = self.layer2(xt)
        xt = tf.keras.activations.softplus(xt)

        xt = self.layer3(xt)

        x_total.append(xt)

        input_temp = []
        input_temp.append(input_rvec[0])
        input_temp.append(input_rvec[2])
        input_temp.append(input_rvec[1])

        input_rvect = tf.concat(input_temp, axis=(1))
        input = tf.reshape(input_rvect, [500, -1])
        xt = self.layer1(input)
        xt = tf.keras.activations.softplus(xt)

        xt = self.layer2(xt)
        xt = tf.keras.activations.softplus(xt)

        xt = self.layer3(xt)

        x_total.append(xt)

        input_temp = []
        input_temp.append(input_rvec[1])
        input_temp.append(input_rvec[0])
        input_temp.append(input_rvec[2])

        input_rvect = tf.concat(input_temp, axis=(1))
        input = tf.reshape(input_rvect, [500, -1])
        xt = self.layer1(input)
        xt = tf.keras.activations.softplus(xt)

        xt = self.layer2(xt)
        xt = tf.keras.activations.softplus(xt)

        xt = self.layer3(xt)

        x_total.append(xt)

        input_temp = []
        input_temp.append(input_rvec[1])
        input_temp.append(input_rvec[2])
        input_temp.append(input_rvec[0])

        input_rvect = tf.concat(input_temp, axis=(1))
        input = tf.reshape(input_rvect, [500, -1])
        xt = self.layer1(input)
        xt = tf.keras.activations.softplus(xt)

        xt = self.layer2(xt)
        xt = tf.keras.activations.softplus(xt)

        xt = self.layer3(xt)

        x_total.append(xt)

        input_temp = []
        input_temp.append(input_rvec[2])
        input_temp.append(input_rvec[1])
        input_temp.append(input_rvec[0])

        input_rvect = tf.concat(input_temp, axis=(1))
        input = tf.reshape(input_rvect, [500, -1])
        xt = self.layer1(input)
        xt = tf.keras.activations.softplus(xt)

        xt = self.layer2(xt)
        xt = tf.keras.activations.softplus(xt)

        xt = self.layer3(xt)

        x_total.append(xt)

        input_temp = []
        input_temp.append(input_rvec[2])
        input_temp.append(input_rvec[0])
        input_temp.append(input_rvec[1])

        input_rvect = tf.concat(input_temp, axis=(1))
        input = tf.reshape(input_rvect, [500, -1])
        xt = self.layer1(input)
        xt = tf.keras.activations.softplus(xt)

        xt = self.layer2(xt)
        xt = tf.keras.activations.softplus(xt)

        xt = self.layer3(xt)

        x_total.append(xt)

        x = 0.0
        for i in range(len(x_total)):
          x = x + x_total[i]   # 즉 x  =  r1+r2+r3    +    r1+r3+r2    +    r2+r1+r3    +    r2+r3+r1    +    r3+r1+r2    +    r3+r2+r1      ##r 1개의 종류는 500개 단 같은 차원 워커끼리만 합친다.
        x = x / math.factorial(part)
        

            
        return x + rRboundary_condition + Rboundary2_condition, tf.exp(x + rRboundary_condition + Rboundary2_condition)    # sigam(r123) + e^(aR²) + e^(a|R-r|),  e^(sigam(r123)) + aR² + a|R-r|



        #x2 = tf.keras.activations.tanh(x2)
        
### 20220907 modified #############################################################
        

        
        # print('input print1', input_rvec)
        # input_rvec1 = input_rvec
        # input_rvec2 = input_rvec

        # input_rvec = (input_rvec1)
        # print('input print0', input_rvec)

        # input_rvec = tf.concat(input_rvec, axis=(1))
        # print('input print2', input_rvec)        
        # input = tf.reshape(input_rvec, [500, -1])
        # print('input print3', input)


        # x1 = self.layer1(input)
        # x1 = tf.keras.activations.softplus(x1)

        # x1 = self.layer2(x1)
        # x1 = tf.keras.activations.softplus(x1)

        # x1 = self.layer3(x1)
        # #x1 = tf.keras.activations.tanh(x1)


        # ###### x2
        # print('input print1', input_rvec)
        # input_rvec = []
        # input_rvec.append(input_rvec2[1])
        # input_rvec.append(input_rvec2[0])


        # print('input print0', input_rvec)

        # input_rvec = tf.concat(input_rvec, axis=(1))
        # print('input print2', input_rvec)        
        # input = tf.reshape(input_rvec, [500, -1])
        # print('input print3', input)


        # x2 = self.layer1(input)
        # x2 = tf.keras.activations.softplus(x2)

        # x2 = self.layer2(x2)
        # x2 = tf.keras.activations.softplus(x2)

        # x2 = self.layer3(x2)
        # #x2 = tf.keras.activations.tanh(x2)

        # x = (x1 + x2)/2.0
        # print('print x' ,x)

        # return x + rRboundary_condition + Rboundary2_condition, tf.exp(x + rRboundary_condition + Rboundary2_condition)

### 20220907 modified #############################################################

ground_state = NeuralWavefunction(3, initial_containment1 = 0.5, initial_containment2 = 0.5)

class MetropolisSampler(object):
    def __init__(self,
        n           : int,
        npart       : int,
        nwalkers    : int,
        initializer : callable,
        init_params : iter ,
        dtype       = tf.float64):

        # dimension:
        self.n = n

        # particle:
        self.npart = npart

        # walkers number:
        self.nwalkers = nwalkers

        self.size = (self.nwalkers, self.npart, self.n)

        self.dtype = dtype

        self.walkers = initializer(shape=self.size, **init_params, dtype=dtype) # 가우시안 분포에 곱해진 워커

    def part(self):
        return  self.npart
    
    def sample(self):
        return  self.walkers

    def kick(self,
        wavefunction : tf.keras.models.Model,
        kicker : callable,
        kicker_params : iter,
        nkicks : int ):
        
        walkers, acceptance = self.internal_kicker(self.size, self.walkers, wavefunction, kicker, kicker_params, tf.constant(nkicks), dtype=self.dtype)
        self.walkers = walkers

        return acceptance

    @tf.function
    def internal_kicker(self,
        _shape,
        _walkers,
        _wavefunction : tf.keras.models.Model,
        _kicker : callable,
        _kicker_params : iter,
        _nkicks : tf.constant,
        dtype):
      
        acceptance = tf.convert_to_tensor(0.0, dtype=dtype)

        current_wavefunction, non_log= _wavefunction(_walkers)

        random_numbers = tf.math.log(tf.random.uniform(shape = [_nkicks, _shape[0], 1], dtype=dtype))

        kicks = _kicker(shape=[_nkicks, *_shape], **_kicker_params, dtype=dtype) # 특정 평균,표준편차를 가지는 가우시안 분포를 가지는 5000개 난수 값 만들기

        for i_kick in tf.range(_nkicks):
            kick = kicks[i_kick]
            kicked = _walkers + kick  # 가우시안 분포에 곱해진 워커에 가우시안 난수값들을 같은차원끼리 더해준다

            kicked_wavefunction, non_log = _wavefunction(kicked)
            probability = 2 * (kicked_wavefunction - current_wavefunction) # 2 (움직인 입자(워커)들의 waveform - 움직이기 전 waveform)
            accept      = probability >  random_numbers[i_kick] ####################################################################################### 랜덤한 0을 가지는 파동함수?! 다시 공부
            current_wavefunction = tf.where(accept, kicked_wavefunction, current_wavefunction)   # probability이 random_numbers[i_kick]보다 크면 kicked_wavefunction 출력 아니면 current_wavefunction 유지 출력

            accept = tf.tile(accept, [1,tf.reduce_prod(_shape[1:])])
            accept = tf.reshape(accept, _shape)
            _walkers = tf.where(accept, kicked, _walkers)
            acceptance = tf.reduce_mean(tf.cast(accept, dtype))

        return _walkers, acceptance

sampler = MetropolisSampler(
            n           = 3, # 3 dimensions
            npart       = 3,
            nwalkers    = N_WALKERS,
            initializer = tf.random.normal,
            init_params = {"mean": 0.0, "stddev" : 0.3},
            dtype       = DEFAULT_TENSOR_TYPE
    )

ground_x = sampler.sample()

print(ground_x.shape)
print(tf.reduce_mean(ground_x))
print(tf.math.reduce_std(ground_x))

values, valus_non_log = ground_state(ground_x)
ground_state.summary()
print(values.shape)

view_ri = 0
ground_x = sampler.sample()
wolker_npart = ground_x.shape[1]
print("particle =", wolker_npart)
for i in range(wolker_npart):
  view_wolkeri = tf.split(ground_x, wolker_npart, axis=(1))[i]
  view_wolkeri = tf.reduce_sum(view_wolkeri, axis=(1))
  r_i_thermalization = tf.sqrt(tf.reduce_sum(view_wolkeri**2, axis=1))
  view_ri = view_ri + r_i_thermalization

acceptance = sampler.kick(
    wavefunction  = ground_state ,
    kicker        = tf.random.normal,
    kicker_params = {"mean": 0.0, "stddev" : 0.3},
    nkicks        = 5000)

view_rf = 0
ground_x = sampler.sample()
wolker_npart = ground_x.shape[1]
for i in range(wolker_npart):
  view_wolkeri = tf.split(ground_x, wolker_npart, axis=(1))[i]
  view_wolkeri = tf.reduce_sum(view_wolkeri, axis=(1))
  r_f_thermalization = tf.sqrt(tf.reduce_sum(view_wolkeri**2, axis=1))
  view_rf = view_rf + r_f_thermalization
print("Acceptance: ", acceptance)

view_ri_mean = view_ri/wolker_npart
view_rf_mean = view_rf/wolker_npart

bins = numpy.arange(0,10,0.5)

print(f"Mean r before thermalization: {tf.reduce_mean(view_ri_mean):.4f}")
print(f"Mean r after thermalization: {tf.reduce_mean(view_rf_mean):.4f}")

before_hist, edges = numpy.histogram(view_ri_mean, bins=bins)
after_hist,  edges = numpy.histogram(view_rf_mean, bins=bins)

bin_centers = 0.5*(edges[1:] + edges[:-1])


fig = plt.figure(figsize=(16,9))
plt.plot(bin_centers, before_hist, marker="+", label="Before Therm.")
plt.plot(bin_centers, after_hist, marker="o", label="After Therm.")
plt.grid(True)
plt.legend()
#plt.show()

print(acceptance)

class HydrogenAtom(object):

    def __init__(self, sampler):

        object.__init__(self)
        # Natural Unit constant
        self.dimension = tf.constant(3, dtype = DEFAULT_TENSOR_TYPE2)
        self.fm = tf.constant(fm, dtype = DEFAULT_TENSOR_TYPE2)
        self.fm2 = self.fm**2
        self.ifm = tf.constant(fm_inverse, dtype = DEFAULT_TENSOR_TYPE2)
        self.ifm2 = self.ifm**2
        self.epsilon0 = tf.constant(epsilon0, dtype = DEFAULT_TENSOR_TYPE2)
        self.mass = m
        self.MeV = tf.constant(MeV, dtype = DEFAULT_TENSOR_TYPE2)
        self.hbar = tf.constant(hbar, dtype = DEFAULT_TENSOR_TYPE2)
        self.c = tf.constant(c, dtype = DEFAULT_TENSOR_TYPE2)
        self.hbarc = tf.constant(hbarc, dtype = DEFAULT_TENSOR_TYPE2)
        self.alpha = tf.constant(alpha, dtype = DEFAULT_TENSOR_TYPE2)


        # Harmonic Oscillator constant
        self.hbaromega = tf.constant(32.0 , dtype = DEFAULT_TENSOR_TYPE2)*self.MeV
        self.harmonic_constant = tf.constant(3.0/2.0, dtype = DEFAULT_TENSOR_TYPE2)

        # Particle n

        self.npart = sampler.part()
        
        # Potential constant type 1 
        # self.V_R0 = tf.constant(341.20*MeV, dtype = DEFAULT_TENSOR_TYPE2)
        # self.V_R2 = tf.constant(-46.55/6.0*MeV, dtype = DEFAULT_TENSOR_TYPE2)
        # self.V_R4 = tf.constant(00.0*MeV, dtype = DEFAULT_TENSOR_TYPE2)
        # self.V_A0 = tf.constant(106.58*MeV, dtype = DEFAULT_TENSOR_TYPE2)   
        # self.V_A2 = tf.constant(18.05/6.0*MeV, dtype = DEFAULT_TENSOR_TYPE2)


        # Potential constant type 2
        self.V_R0 = tf.constant(364.20*MeV, dtype = DEFAULT_TENSOR_TYPE2)
        self.V_R2 = tf.constant(-223.28/20.0*MeV, dtype = DEFAULT_TENSOR_TYPE2)
        self.V_R4 = tf.constant(00.0*MeV, dtype = DEFAULT_TENSOR_TYPE2)
        self.V_A0 = tf.constant(110.73*MeV, dtype = DEFAULT_TENSOR_TYPE2)   
        self.V_A2 = tf.constant(48.36/20.0*MeV, dtype = DEFAULT_TENSOR_TYPE2)        

        self.mu_R0 = tf.constant(0.7*fm_inverse, dtype = DEFAULT_TENSOR_TYPE2)
        self.mu_A0 = tf.constant(0.475*fm_inverse, dtype = DEFAULT_TENSOR_TYPE2)



        # Three body potential constant 
#        self.V03   = tf.constant(-1320.0*MeV, dtype = DEFAULT_TENSOR_TYPE2)
        self.V03   = tf.constant(0.0*MeV, dtype = DEFAULT_TENSOR_TYPE2)
#        self.V03   = tf.constant(-7.0*MeV, dtype = DEFAULT_TENSOR_TYPE2)
        self.lamb  = tf.constant(0.506*10.0**(-2.0)*self.ifm**2.0,dtype=DEFAULT_TENSOR_TYPE2)
#        self.lamb  = tf.constant(0.225625*self.ifm**2.0,dtype=DEFAULT_TENSOR_TYPE2)
#        self.lamb  = tf.constant(0.21792*self.ifm**2.0,dtype=DEFAULT_TENSOR_TYPE2)
        
    # @tf.function
    def energy(self, wavefunction : tf.keras.models.Model, inputs : tf.Tensor):

        inputs = tf.cast(inputs, DEFAULT_TENSOR_TYPE2)
        logw_of_x, dlogw_dx, d2logw_dx2, w_of_x, dw_dx, d2w_dx2, beforein = self.compute_derivatives(wavefunction, inputs)
        # logw_of_x, dlogw_dx, d2logw_dx2 = self.compute_derivatives(wavefunction, inputs)


        pe, ke_direct, interaction_e = self.compute_energies(inputs, logw_of_x, dlogw_dx, d2logw_dx2, w_of_x, dw_dx, d2w_dx2, beforein)
        # pe, ke_direct, interaction_e = self.compute_energies(inputs, logw_of_x, dlogw_dx, d2logw_dx2)

        energy = ke_direct + interaction_e
        energy = energy - (self.harmonic_constant * self.hbaromega)
        energy = tf.squeeze(energy/self.MeV)
        return tf.cast(energy, DEFAULT_TENSOR_TYPE)

    @tf.function
    def compute_derivatives(self, wavefunction : tf.keras.models.Model, inputs : tf.Tensor):

        with tf.GradientTape(persistent=True) as tape:
            tape.watch(inputs)
            with tf.GradientTape() as second_tape:
                second_tape.watch(inputs)
                logw_of_x = wavefunction(inputs, training=True)
            
            dlogw_dx = second_tape.gradient(logw_of_x, inputs)
        d2logw_dx2 = tape.batch_jacobian(dlogw_dx, inputs)
        beforein = d2logw_dx2
        d2logw_dx2 = tf.einsum("wvdvd->wvd",beforein)
        # d2logw_dx2 = tf.einsum("wvdvd->wvd",d2logw_dx2)
        print(beforein, d2logw_dx2,'#####before and d2logw_dx2######')


        with tf.GradientTape(persistent=True) as tape:
            tape.watch(inputs)
            with tf.GradientTape() as second_tape:
                second_tape.watch(inputs)
                logw_of_x, w_of_x = wavefunction(inputs, training=True)
            
            dw_dx = second_tape.gradient(w_of_x, inputs)
        d2w_dx2 = tape.batch_jacobian(dw_dx, inputs)
        # beforein = d2w_dx2

        # d2w_dx2 = tf.einsum("wvdvd->wvd",d2w_dx2)
        d2w_dx2 = tf.einsum("wvdvd->wvd",beforein)

        # print(beforein, d2w_dx2,'before and d2w_dx2')

        #d2logw_dx2= tf.reshape(d2logw_dx2, [500, -1])
        #dlogw_dx= tf.reshape(dlogw_dx, [500, -1])

        return logw_of_x, dlogw_dx, d2logw_dx2, w_of_x, dw_dx, d2w_dx2, beforein


    @tf.function
    def potential_energy(self, *, inputs, Z):
        pe = tf.constant(0, dtype = DEFAULT_TENSOR_TYPE2)
        #npart = self.npart #파티클 수
        #for i in range(npart):
        #  _wolkeri = tf.split(inputs, npart, axis=(1))[i]
        #  _wolkeri = tf.reduce_sum(_wolkeri, axis=(1))
        #  r_i_thermalization = tf.sqrt(tf.reduce_sum(_wolkeri**2, axis=1))
        #  pe_1 = - (Z * self.alpha * self.HBARC * (1. /(r_i_thermalization + 1e-8)))
        #  pe = pe + pe_1

        return pe

    @tf.function
    def interaction_energy(self, *, logw_of_x, dlogw_dx, d2logw_dx2, inputs, beforein):
        interaction3 = 0
        Vr = 0
        #Vr0 = 0
        sum_mr = 0
        M_total = 0

        for i in range(self.npart):
          hwalker = tf.split(inputs, self.npart, axis=(1))[i]
          hwalker = tf.reduce_sum(hwalker, axis=(1))
          mo = tf.cast((self.mass[i]*self.MeV), dtype= DEFAULT_TENSOR_TYPE2)
          sum_mr = sum_mr + (mo * hwalker)*self.fm
          M_total = M_total + mo
        sum_R = sum_mr / M_total
        sum_R2 = tf.reduce_sum(sum_R**2 , axis =(1))


        ### TWO ALPHA INTERACTION ##############################################

#         if self.npart > 1:
#           for i in range(self.npart-1):
#             walkero = tf.split(inputs, self.npart, axis=(1))[i]
#             for j in range(i+1, self.npart):
#               walkerm = tf.split(inputs, self.npart, axis=(1))[j]
#               dwalker = walkero - walkerm # (500,1, 3) p개
#               walker_dnm = tf.reduce_sum(dwalker, axis=(1))
#               del_r = tf.sqrt(tf.reduce_sum(walker_dnm**2, axis=(1)))
#               del_r_2 = tf.reduce_sum(walker_dnm**2, axis=(1))
#               Vri = self.V_R0*tf.exp(-(self.mu_R0**2)*del_r_2) - self.V_A0*tf.exp(-(self.mu_A0**2)*del_r_2)
#               # pinteraction = 4.0*self.alpha/del_r*tf.math.erf(0.75*del_r)*self.hbarc  #self.alpha*self.hbarc*4.0*(1. /(del_r+1e-8))

# #              pinteraction = tf.cast(pinteraction,dtype= DEFAULT_TEMSOR_TYPE2)
#               Vr = Vr + Vri #+ pinteraction

#           k = M_total* (self.hbaromega**2) / (self.hbarc**2)
#           harmonic_pot = tf.cast(0.5, dtype= DEFAULT_TENSOR_TYPE2) * k * sum_R2
#           interaction = Vr + harmonic_pot
#         else:
#           interaction = 0




         ### ANGULAR MOMENTUM POTENTIAL #######################################
        interaction = 0.0
        if self.npart > 1 :
          for i in range(self.npart-1):
            walker0 = tf.split(inputs, self.npart, axis=(1))[i]
            # walker0 = tf.reduce_sum(walker0,axis=(1))

            # walker0x = tf.split(walker0, 3, axis=(1))[0]
            # walker0x = tf.reduce_sum(walker0x, axis=(1))
            # walker0y = tf.split(walker0, 3, axis=(1))[1]
            # walker0y = tf.reduce_sum(walker0y, axis=(1))
            # walker0z = tf.split(walker0, 3, axis=(1))[2]
            # walker0z = tf.reduce_sum(walker0z, axis=(1))

            # print(walker0)
            # dw_dx0  = tf.split(dw_dx,self.npart,axis=(1))[i]
            # dw_dx0  = tf.reduce_sum(dw_dx0,axis=(1))

            # print(dlogw_dx)
            dlogw_dx0 = tf.split(dlogw_dx, self.npart, axis=(1))[i]
            dlogw_dx0 = tf.reduce_sum(dlogw_dx0, axis=(1))

            d2logw_dx2i = tf.split(d2logw_dx2, self.npart, axis = (1))[i]

            d2logw_dx2i = tf.reduce_sum(d2logw_dx2i, axis=(1))*self.fm2
            

            # print(dlogw_dx0)
            # # dlogw_dx0 = tf.reduce_sum(dlogw_dx0,axis=(1))*self.fm
            # print(dlogw_dx0)
            # dlogw_dx0x = tf.split(dlogw_dx0, 3, axis=(1))[0] ## The 3 means dimension.
            # dlogw_dx0x = tf.reduce_sum(dlogw_dx0x, axis= (1))
            # dlogw_dx0y = tf.split(dlogw_dx0, 3, axis=(1))[1]
            # dlogw_dx0y = tf.reduce_sum(dlogw_dx0y, axis= (1))
            # dlogw_dx0z = tf.split(dlogw_dx0, 3, axis=(1))[2]
            # dlogw_dx0z = tf.reduce_sum(dlogw_dx0z, axis= (1))

            for j in range(i+1, self.npart):

              walker1 = tf.split(inputs, self.npart, axis=(1))[j]
              dlogw_dx1 = tf.split(dlogw_dx, self.npart, axis=(1))[j]
              dlogw_dx1 = tf.reduce_sum(dlogw_dx1, axis=(1))

              print(dlogw_dx0,'dlogw_dx0 !!!!')
              # dlogw_dx0 = tf.reduce_sum(dlogw_dx0, axis=(1))
              dlogw_dx0x = tf.split(dlogw_dx0, 3, axis=(1))[0]
              dlogw_dx0x = tf.reduce_sum(dlogw_dx0x, axis=(1))
              dlogw_dx0y = tf.split(dlogw_dx0, 3, axis=(1))[1]
              dlogw_dx0y = tf.reduce_sum(dlogw_dx0y, axis=(1))
              dlogw_dx0z = tf.split(dlogw_dx0, 3, axis=(1))[2]
              dlogw_dx0z = tf.reduce_sum(dlogw_dx0z, axis=(1))                        
              # dlogw_dx1 = tf.reduce_sum(dlogw_dx1, axis=(1))
              dlogw_dx1x = tf.split(dlogw_dx1, 3, axis=(1))[0]
              dlogw_dx1x = tf.reduce_sum(dlogw_dx1x, axis=(1))
              dlogw_dx1y = tf.split(dlogw_dx1, 3, axis=(1))[1]
              dlogw_dx1y = tf.reduce_sum(dlogw_dx1y, axis=(1))
              dlogw_dx1z = tf.split(dlogw_dx1, 3, axis=(1))[2]
              dlogw_dx1z = tf.reduce_sum(dlogw_dx1z, axis=(1)) 


              dwalker = walker1 - walker0
              dwalker = tf.reduce_sum(dwalker, axis=(1))
            

              array_dwalker = []
              dwalkerx = tf.split(dwalker, 3, axis=(1))[0]
              dwalkerx = tf.reduce_sum(dwalkerx, axis=(1))
              array_dwalker.append(dwalkerx)
              dwalkery = tf.split(dwalker, 3, axis=(1))[1]
              dwalkery = tf.reduce_sum(dwalkery, axis=(1))
              array_dwalker.append(dwalkery)
              dwalkerz = tf.split(dwalker, 3, axis=(1))[2]
              dwalkerz = tf.reduce_sum(dwalkerz, axis=(1))
              array_dwalker.append(dwalkerz)

              ddlogw_dx = dlogw_dx1 - dlogw_dx0
              # ddlogw_dx = tf.reduce_sum(ddlogw_dx, axis=(1))

              array_ddlogw_dx = []
              # ddlogw_dx = tf.split(ddlogw_dx, self.npart, axis=(1))[i]
              # ddlogw_dx = tf.reduce_sum(ddlogw_dx,axis=(1))*self.fm
              ddlogw_dx0x = tf.split(ddlogw_dx, 3, axis=(1))[0] ## The 3 means dimension.
              ddlogw_dx0x = tf.reduce_sum(ddlogw_dx0x, axis= (1))
              array_ddlogw_dx.append(ddlogw_dx0x)
              ddlogw_dx0y = tf.split(ddlogw_dx, 3, axis=(1))[1]
              ddlogw_dx0y = tf.reduce_sum(ddlogw_dx0y, axis= (1))
              array_ddlogw_dx.append(ddlogw_dx0y)
              ddlogw_dx0z = tf.split(ddlogw_dx, 3, axis=(1))[2]
              ddlogw_dx0z = tf.reduce_sum(ddlogw_dx0z, axis= (1))              
              array_ddlogw_dx.append(ddlogw_dx0z)
              print(array_dwalker[0],'array_dwalker[0]')


              d2logw_dx2i = tf.split(d2logw_dx2, self.npart, axis = (1))[j]
              d2logw_dx2i = tf.reduce_sum(d2logw_dx2i, axis=(1))*self.fm2


              ## From here term1
              term1 = (array_dwalker[0]*array_ddlogw_dx[0] + array_dwalker[1]*array_ddlogw_dx[1] 
                       + array_dwalker[2]*array_ddlogw_dx[2])
              term1 = 0.5*term1





              ## From here term3

              term3 = 0.0
              partial = beforein
              print(beforein)

              print('test')
              print(beforein[499][1][2][1][2],'before[300][1][2][1][2]')

              print('partial--xx start')
              partialaaxx = tf.split(partial, self.npart,axis=(1))[i]
              partialaaxx = tf.reduce_sum(partialaaxx, axis=(1))
              partialaaxx = tf.split(partialaaxx, 3, axis=(1))[0]
              partialaaxx = tf.reduce_sum(partialaaxx, axis=(1))
              partialaaxx = tf.split(partialaaxx, self.npart,axis=(1))[i]
              partialaaxx = tf.reduce_sum(partialaaxx, axis=(1))
              partialaaxx = tf.split(partialaaxx, 3, axis=(1))[0]
              partialaaxx = tf.reduce_sum(partialaaxx, axis=(1))
              print(partialaaxx)                                        # it means (\pairtial(a)_x\x - \partial(a)_\x)
              
              partialabxx = tf.split(partial, self.npart,axis=(1))[i]
              partialabxx = tf.reduce_sum(partialabxx, axis=(1))
              partialabxx = tf.split(partialabxx, 3, axis=(1))[0]
              partialabxx = tf.reduce_sum(partialabxx, axis=(1))
              partialabxx = tf.split(partialabxx, self.npart,axis=(1))[j]
              partialabxx = tf.reduce_sum(partialabxx, axis=(1))
              partialabxx = tf.split(partialabxx, 3, axis=(1))[0]
              partialabxx = tf.reduce_sum(partialabxx, axis=(1))
              print(partialabxx)

              partialbaxx = tf.split(partial, self.npart,axis=(1))[j]
              partialbaxx = tf.reduce_sum(partialbaxx, axis=(1))
              partialbaxx = tf.split(partialbaxx, 3, axis=(1))[0]
              partialbaxx = tf.reduce_sum(partialbaxx, axis=(1))
              partialbaxx = tf.split(partialbaxx, self.npart,axis=(1))[i]
              partialbaxx = tf.reduce_sum(partialbaxx, axis=(1))
              partialbaxx = tf.split(partialbaxx, 3, axis=(1))[0]
              partialbaxx = tf.reduce_sum(partialbaxx, axis=(1))
              print(partialbaxx)

              partialbbxx = tf.split(partial, self.npart,axis=(1))[j]
              partialbbxx = tf.reduce_sum(partialbbxx, axis=(1))
              partialbbxx = tf.split(partialbbxx, 3, axis=(1))[0]
              partialbbxx = tf.reduce_sum(partialbbxx, axis=(1))
              partialbbxx = tf.split(partialbbxx, self.npart,axis=(1))[j]
              partialbbxx = tf.reduce_sum(partialbbxx, axis=(1))
              partialbbxx = tf.split(partialbbxx, 3, axis=(1))[0]
              partialbbxx = tf.reduce_sum(partialbbxx, axis=(1)) 
              print(partialbbxx)    
              term3 = term3 + (array_dwalker[0]*array_dwalker[0]*
                               (partialaaxx - partialabxx - partialbaxx + partialbbxx
                                + array_ddlogw_dx[0]*array_ddlogw_dx[0]))
                                # + dlogw_dx0x*dlogw_dx0x - dlogw_dx0x*dlogw_dx1x - dlogw_dx1x*dlogw_dx0x + dlogw_dx1x*dlogw_dx1x ))
              print('partial--xx end')



              print('partial--xy start')
              partialaaxy = tf.split(partial, self.npart,axis=(1))[i]
              partialaaxy = tf.reduce_sum(partialaaxy, axis=(1))
              partialaaxy = tf.split(partialaaxy, 3, axis=(1))[0]
              partialaaxy = tf.reduce_sum(partialaaxy, axis=(1))
              partialaaxy = tf.split(partialaaxy, self.npart,axis=(1))[i]
              partialaaxy = tf.reduce_sum(partialaaxy, axis=(1))
              partialaaxy = tf.split(partialaaxy, 3, axis=(1))[1]
              partialaaxy = tf.reduce_sum(partialaaxy, axis=(1))
              print(partialaaxy)
              
              partialabxy = tf.split(partial, self.npart,axis=(1))[i]
              partialabxy = tf.reduce_sum(partialabxy, axis=(1))
              partialabxy = tf.split(partialabxy, 3, axis=(1))[0]
              partialabxy = tf.reduce_sum(partialabxy, axis=(1))
              partialabxy = tf.split(partialabxy, self.npart,axis=(1))[j]
              partialabxy = tf.reduce_sum(partialabxy, axis=(1))
              partialabxy = tf.split(partialabxy, 3, axis=(1))[1]
              partialabxy = tf.reduce_sum(partialabxy, axis=(1))
              print(partialabxy)

              partialbaxy = tf.split(partial, self.npart,axis=(1))[j]
              partialbaxy = tf.reduce_sum(partialbaxy, axis=(1))
              partialbaxy = tf.split(partialbaxy, 3, axis=(1))[0]
              partialbaxy = tf.reduce_sum(partialbaxy, axis=(1))
              partialbaxy = tf.split(partialbaxy, self.npart,axis=(1))[i]
              partialbaxy = tf.reduce_sum(partialbaxy, axis=(1))
              partialbaxy = tf.split(partialbaxy, 3, axis=(1))[1]
              partialbaxy = tf.reduce_sum(partialbaxy, axis=(1))
              print(partialbaxy)

              partialbbxy = tf.split(partial, self.npart,axis=(1))[j]
              partialbbxy = tf.reduce_sum(partialbbxy, axis=(1))
              partialbbxy = tf.split(partialbbxy, 3, axis=(1))[0]
              partialbbxy = tf.reduce_sum(partialbbxy, axis=(1))
              partialbbxy = tf.split(partialbbxy, self.npart,axis=(1))[j]
              partialbbxy = tf.reduce_sum(partialbbxy, axis=(1))
              partialbbxy = tf.split(partialbbxy, 3, axis=(1))[1]
              partialbbxy = tf.reduce_sum(partialbbxy, axis=(1)) 
              print(partialbbxy)
              term3 = term3 + (array_dwalker[0]*array_dwalker[1]*
                               (partialaaxy - partialabxy - partialbaxy + partialbbxy
                                + array_ddlogw_dx[0]*array_ddlogw_dx[1]))
                                # + dlogw_dx0x*dlogw_dx0y - dlogw_dx0x*dlogw_dx1y - dlogw_dx1x*dlogw_dx0y + dlogw_dx1x*dlogw_dx1y))  
              print('partial--xy end')


              

              print('partial--xz start')
              partialaaxz = tf.split(partial, self.npart,axis=(1))[i]
              partialaaxz = tf.reduce_sum(partialaaxz, axis=(1))
              partialaaxz = tf.split(partialaaxz, 3, axis=(1))[0]
              partialaaxz = tf.reduce_sum(partialaaxz, axis=(1))
              partialaaxz = tf.split(partialaaxz, self.npart,axis=(1))[i]
              partialaaxz = tf.reduce_sum(partialaaxz, axis=(1))
              partialaaxz = tf.split(partialaaxz, 3, axis=(1))[2]
              partialaaxz = tf.reduce_sum(partialaaxz, axis=(1))
              print(partialaaxz)
              
              partialabxz = tf.split(partial, self.npart,axis=(1))[i]
              partialabxz = tf.reduce_sum(partialabxz, axis=(1))
              partialabxz = tf.split(partialabxz, 3, axis=(1))[0]
              partialabxz = tf.reduce_sum(partialabxz, axis=(1))
              partialabxz = tf.split(partialabxz, self.npart,axis=(1))[j]
              partialabxz = tf.reduce_sum(partialabxz, axis=(1))
              partialabxz = tf.split(partialabxz, 3, axis=(1))[2]
              partialabxz = tf.reduce_sum(partialabxz, axis=(1))
              print(partialabxz)

              partialbaxz = tf.split(partial, self.npart,axis=(1))[j]
              partialbaxz = tf.reduce_sum(partialbaxz, axis=(1))
              partialbaxz = tf.split(partialbaxz, 3, axis=(1))[0]
              partialbaxz = tf.reduce_sum(partialbaxz, axis=(1))
              partialbaxz = tf.split(partialbaxz, self.npart,axis=(1))[i]
              partialbaxz = tf.reduce_sum(partialbaxz, axis=(1))
              partialbaxz = tf.split(partialbaxz, 3, axis=(1))[2]
              partialbaxz = tf.reduce_sum(partialbaxz, axis=(1))
              print(partialbaxz)

              partialbbxz = tf.split(partial, self.npart,axis=(1))[j]
              partialbbxz = tf.reduce_sum(partialbbxz, axis=(1))
              partialbbxz = tf.split(partialbbxz, 3, axis=(1))[0]
              partialbbxz = tf.reduce_sum(partialbbxz, axis=(1))
              partialbbxz = tf.split(partialbbxz, self.npart,axis=(1))[j]
              partialbbxz = tf.reduce_sum(partialbbxz, axis=(1))
              partialbbxz = tf.split(partialbbxz, 3, axis=(1))[2]
              partialbbxz = tf.reduce_sum(partialbbxz, axis=(1)) 
              print(partialbbxz)   
              term3 = term3 + (array_dwalker[0]*array_dwalker[2]*
                               (partialaaxz - partialabxz - partialbaxz + partialbbxz
                                + array_ddlogw_dx[0]*array_ddlogw_dx[2]))
                                # + dlogw_dx0x*dlogw_dx0z - dlogw_dx0x*dlogw_dx1z - dlogw_dx1x*dlogw_dx0z + dlogw_dx1x*dlogw_dx1z)) 
              print('partial--xz end')




              print('partial--yx start')
              partialaayx = tf.split(partial, self.npart,axis=(1))[i]
              partialaayx = tf.reduce_sum(partialaayx, axis=(1))
              partialaayx = tf.split(partialaayx, 3, axis=(1))[1]
              partialaayx = tf.reduce_sum(partialaayx, axis=(1))
              partialaayx = tf.split(partialaayx, self.npart,axis=(1))[i]
              partialaayx = tf.reduce_sum(partialaayx, axis=(1))
              partialaayx = tf.split(partialaayx, 3, axis=(1))[0]
              partialaayx = tf.reduce_sum(partialaayx, axis=(1))
              print(partialaayx)
              
              partialabyx = tf.split(partial, self.npart,axis=(1))[i]
              partialabyx = tf.reduce_sum(partialabyx, axis=(1))
              partialabyx = tf.split(partialabyx, 3, axis=(1))[1]
              partialabyx = tf.reduce_sum(partialabyx, axis=(1))
              partialabyx = tf.split(partialabyx, self.npart,axis=(1))[j]
              partialabyx = tf.reduce_sum(partialabyx, axis=(1))
              partialabyx = tf.split(partialabyx, 3, axis=(1))[0]
              partialabyx = tf.reduce_sum(partialabyx, axis=(1))
              print(partialabyx)

              partialbayx = tf.split(partial, self.npart,axis=(1))[j]
              partialbayx = tf.reduce_sum(partialbayx, axis=(1))
              partialbayx = tf.split(partialbayx, 3, axis=(1))[1]
              partialbayx = tf.reduce_sum(partialbayx, axis=(1))
              partialbayx = tf.split(partialbayx, self.npart,axis=(1))[i]
              partialbayx = tf.reduce_sum(partialbayx, axis=(1))
              partialbayx = tf.split(partialbayx, 3, axis=(1))[0]
              partialbayx = tf.reduce_sum(partialbayx, axis=(1))
              print(partialbayx)

              partialbbyx = tf.split(partial, self.npart,axis=(1))[j]
              partialbbyx = tf.reduce_sum(partialbbyx, axis=(1))
              partialbbyx = tf.split(partialbbyx, 3, axis=(1))[1]
              partialbbyx = tf.reduce_sum(partialbbyx, axis=(1))
              partialbbyx = tf.split(partialbbyx, self.npart,axis=(1))[j]
              partialbbyx = tf.reduce_sum(partialbbyx, axis=(1))
              partialbbyx = tf.split(partialbbyx, 3, axis=(1))[0]
              partialbbyx = tf.reduce_sum(partialbbyx, axis=(1)) 
              print(partialbbyx)   
              term3 = term3 + (array_dwalker[1]*array_dwalker[0]*
                               (partialaayx - partialabyx - partialbayx + partialbbyx
                                + array_ddlogw_dx[1]*array_ddlogw_dx[0]))
                                # + dlogw_dx0y*dlogw_dx0x - dlogw_dx0y*dlogw_dx1x - dlogw_dx1y*dlogw_dx0x + dlogw_dx1y*dlogw_dx1x)) 
              print('partial--yx end')


              print('partial--yy start')
              partialaayy = tf.split(partial, self.npart,axis=(1))[i]
              partialaayy = tf.reduce_sum(partialaayy, axis=(1))
              partialaayy = tf.split(partialaayy, 3, axis=(1))[1]
              partialaayy = tf.reduce_sum(partialaayy, axis=(1))
              partialaayy = tf.split(partialaayy, self.npart,axis=(1))[i]
              partialaayy = tf.reduce_sum(partialaayy, axis=(1))
              partialaayy = tf.split(partialaayy, 3, axis=(1))[1]
              partialaayy = tf.reduce_sum(partialaayy, axis=(1))
              print(partialaayy)
              
              partialabyy = tf.split(partial, self.npart,axis=(1))[i]
              partialabyy = tf.reduce_sum(partialabyy, axis=(1))
              partialabyy = tf.split(partialabyy, 3, axis=(1))[1]
              partialabyy = tf.reduce_sum(partialabyy, axis=(1))
              partialabyy = tf.split(partialabyy, self.npart,axis=(1))[j]
              partialabyy = tf.reduce_sum(partialabyy, axis=(1))
              partialabyy = tf.split(partialabyy, 3, axis=(1))[1]
              partialabyy = tf.reduce_sum(partialabyy, axis=(1))
              print(partialabyy)

              partialbayy = tf.split(partial, self.npart,axis=(1))[j]
              partialbayy = tf.reduce_sum(partialbayy, axis=(1))
              partialbayy = tf.split(partialbayy, 3, axis=(1))[1]
              partialbayy = tf.reduce_sum(partialbayy, axis=(1))
              partialbayy = tf.split(partialbayy, self.npart,axis=(1))[i]
              partialbayy = tf.reduce_sum(partialbayy, axis=(1))
              partialbayy = tf.split(partialbayy, 3, axis=(1))[1]
              partialbayy = tf.reduce_sum(partialbayy, axis=(1))
              print(partialbayy)

              partialbbyy = tf.split(partial, self.npart,axis=(1))[j]
              partialbbyy = tf.reduce_sum(partialbbyy, axis=(1))
              partialbbyy = tf.split(partialbbyy, 3, axis=(1))[1]
              partialbbyy = tf.reduce_sum(partialbbyy, axis=(1))
              partialbbyy = tf.split(partialbbyy, self.npart,axis=(1))[j]
              partialbbyy = tf.reduce_sum(partialbbyy, axis=(1))
              partialbbyy = tf.split(partialbbyy, 3, axis=(1))[1]
              partialbbyy = tf.reduce_sum(partialbbyy, axis=(1)) 
              print(partialbbyy)    
              term3 = term3 + (array_dwalker[1]*array_dwalker[1]*
                               (partialaayy - partialabyy - partialbayy + partialbbyy
                                + array_ddlogw_dx[1]*array_ddlogw_dx[1]))
                                # + dlogw_dx0y*dlogw_dx0y - dlogw_dx0y*dlogw_dx1y - dlogw_dx1y*dlogw_dx0y + dlogw_dx1y*dlogw_dx1y))
              print('partial--yy end')

              
              print('partial--yz start')
              partialaayz = tf.split(partial, self.npart,axis=(1))[i]
              partialaayz = tf.reduce_sum(partialaayz, axis=(1))
              partialaayz = tf.split(partialaayz, 3, axis=(1))[1]
              partialaayz = tf.reduce_sum(partialaayz, axis=(1))
              partialaayz = tf.split(partialaayz, self.npart,axis=(1))[i]
              partialaayz = tf.reduce_sum(partialaayz, axis=(1))
              partialaayz = tf.split(partialaayz, 3, axis=(1))[2]
              partialaayz = tf.reduce_sum(partialaayz, axis=(1))
              print(partialaayz)
              
              partialabyz = tf.split(partial, self.npart,axis=(1))[i]
              partialabyz = tf.reduce_sum(partialabyz, axis=(1))
              partialabyz = tf.split(partialabyz, 3, axis=(1))[1]
              partialabyz = tf.reduce_sum(partialabyz, axis=(1))
              partialabyz = tf.split(partialabyz, self.npart,axis=(1))[j]
              partialabyz = tf.reduce_sum(partialabyz, axis=(1))
              partialabyz = tf.split(partialabyz, 3, axis=(1))[2]
              partialabyz = tf.reduce_sum(partialabyz, axis=(1))
              print(partialabyz)

              partialbayz = tf.split(partial, self.npart,axis=(1))[j]
              partialbayz = tf.reduce_sum(partialbayz, axis=(1))
              partialbayz = tf.split(partialbayz, 3, axis=(1))[1]
              partialbayz = tf.reduce_sum(partialbayz, axis=(1))
              partialbayz = tf.split(partialbayz, self.npart,axis=(1))[i]
              partialbayz = tf.reduce_sum(partialbayz, axis=(1))
              partialbayz = tf.split(partialbayz, 3, axis=(1))[2]
              partialbayz = tf.reduce_sum(partialbayz, axis=(1))
              print(partialbayz)

              partialbbyz = tf.split(partial, self.npart,axis=(1))[j]
              partialbbyz = tf.reduce_sum(partialbbyz, axis=(1))
              partialbbyz = tf.split(partialbbyz, 3, axis=(1))[1]
              partialbbyz = tf.reduce_sum(partialbbyz, axis=(1))
              partialbbyz = tf.split(partialbbyz, self.npart,axis=(1))[j]
              partialbbyz = tf.reduce_sum(partialbbyz, axis=(1))
              partialbbyz = tf.split(partialbbyz, 3, axis=(1))[2]
              partialbbyz = tf.reduce_sum(partialbbyz, axis=(1)) 
              print(partialbbyz)    
              term3 = term3 + (array_dwalker[1]*array_dwalker[2]*
                               (partialaayz - partialabyz - partialbayz + partialbbyz
                                + array_ddlogw_dx[1]*array_ddlogw_dx[2]))
                                # + dlogw_dx0y*dlogw_dx0z - dlogw_dx0y*dlogw_dx1z - dlogw_dx1y*dlogw_dx0z + dlogw_dx1y*dlogw_dx1z))
              print('partial--yz end')
                                                                        



              print('partial--zx start')
              partialaazx = tf.split(partial, self.npart,axis=(1))[i]
              partialaazx = tf.reduce_sum(partialaazx, axis=(1))
              partialaazx = tf.split(partialaazx, 3, axis=(1))[2]
              partialaazx = tf.reduce_sum(partialaazx, axis=(1))
              partialaazx = tf.split(partialaazx, self.npart,axis=(1))[i]
              partialaazx = tf.reduce_sum(partialaazx, axis=(1))
              partialaazx = tf.split(partialaazx, 3, axis=(1))[0]
              partialaazx = tf.reduce_sum(partialaazx, axis=(1))
              print(partialaazx)
              
              partialabzx = tf.split(partial, self.npart,axis=(1))[i]
              partialabzx = tf.reduce_sum(partialabzx, axis=(1))
              partialabzx = tf.split(partialabzx, 3, axis=(1))[2]
              partialabzx = tf.reduce_sum(partialabzx, axis=(1))
              partialabzx = tf.split(partialabzx, self.npart,axis=(1))[j]
              partialabzx = tf.reduce_sum(partialabzx, axis=(1))
              partialabzx = tf.split(partialabzx, 3, axis=(1))[0]
              partialabzx = tf.reduce_sum(partialabzx, axis=(1))
              print(partialabzx)

              partialbazx = tf.split(partial, self.npart,axis=(1))[j]
              partialbazx = tf.reduce_sum(partialbazx, axis=(1))
              partialbazx = tf.split(partialbazx, 3, axis=(1))[2]
              partialbazx = tf.reduce_sum(partialbazx, axis=(1))
              partialbazx = tf.split(partialbazx, self.npart,axis=(1))[i]
              partialbazx = tf.reduce_sum(partialbazx, axis=(1))
              partialbazx = tf.split(partialbazx, 3, axis=(1))[0]
              partialbazx = tf.reduce_sum(partialbazx, axis=(1))
              print(partialbazx)

              partialbbzx = tf.split(partial, self.npart,axis=(1))[j]
              partialbbzx = tf.reduce_sum(partialbbzx, axis=(1))
              partialbbzx = tf.split(partialbbzx, 3, axis=(1))[2]
              partialbbzx = tf.reduce_sum(partialbbzx, axis=(1))
              partialbbzx = tf.split(partialbbzx, self.npart,axis=(1))[j]
              partialbbzx = tf.reduce_sum(partialbbzx, axis=(1))
              partialbbzx = tf.split(partialbbzx, 3, axis=(1))[0]
              partialbbzx = tf.reduce_sum(partialbbzx, axis=(1)) 
              print(partialbbzx)  
              term3 = term3 + (array_dwalker[2]*array_dwalker[0]*
                               (partialaazx - partialabzx - partialbazx + partialbbzx
                                + array_ddlogw_dx[2]*array_ddlogw_dx[0]))
                                # + dlogw_dx0z*dlogw_dx0x - dlogw_dx0z*dlogw_dx1x - dlogw_dx1z*dlogw_dx0x + dlogw_dx1z*dlogw_dx1x))  
              print('partial--zx end')



              print('partial--zy start')
              partialaazy = tf.split(partial, self.npart,axis=(1))[i]
              partialaazy = tf.reduce_sum(partialaazy, axis=(1))
              partialaazy = tf.split(partialaazy, 3, axis=(1))[2]
              partialaazy = tf.reduce_sum(partialaazy, axis=(1))
              partialaazy = tf.split(partialaazy, self.npart,axis=(1))[i]
              partialaazy = tf.reduce_sum(partialaazy, axis=(1))
              partialaazy = tf.split(partialaazy, 3, axis=(1))[1]
              partialaazy = tf.reduce_sum(partialaazy, axis=(1))
              print(partialaazy)
              
              partialabzy = tf.split(partial, self.npart,axis=(1))[i]
              partialabzy = tf.reduce_sum(partialabzy, axis=(1))
              partialabzy = tf.split(partialabzy, 3, axis=(1))[2]
              partialabzy = tf.reduce_sum(partialabzy, axis=(1))
              partialabzy = tf.split(partialabzy, self.npart,axis=(1))[j]
              partialabzy = tf.reduce_sum(partialabzy, axis=(1))
              partialabzy = tf.split(partialabzy, 3, axis=(1))[1]
              partialabzy = tf.reduce_sum(partialabzy, axis=(1))
              print(partialabzy)

              partialbazy = tf.split(partial, self.npart,axis=(1))[j]
              partialbazy = tf.reduce_sum(partialbazy, axis=(1))
              partialbazy = tf.split(partialbazy, 3, axis=(1))[2]
              partialbazy = tf.reduce_sum(partialbazy, axis=(1))
              partialbazy = tf.split(partialbazy, self.npart,axis=(1))[i]
              partialbazy = tf.reduce_sum(partialbazy, axis=(1))
              partialbazy = tf.split(partialbazy, 3, axis=(1))[1]
              partialbazy = tf.reduce_sum(partialbazy, axis=(1))
              print(partialbazy)

              partialbbzy = tf.split(partial, self.npart,axis=(1))[j]
              partialbbzy = tf.reduce_sum(partialbbzy, axis=(1))
              partialbbzy = tf.split(partialbbzy, 3, axis=(1))[2]
              partialbbzy = tf.reduce_sum(partialbbzy, axis=(1))
              partialbbzy = tf.split(partialbbzy, self.npart,axis=(1))[j]
              partialbbzy = tf.reduce_sum(partialbbzy, axis=(1))
              partialbbzy = tf.split(partialbbzy, 3, axis=(1))[1]
              partialbbzy = tf.reduce_sum(partialbbzy, axis=(1)) 
              print(partialbbzy)  
              term3 = term3 + (array_dwalker[2]*array_dwalker[1]*
                               (partialaazy - partialabzy - partialbazy + partialbbzy
                                + array_ddlogw_dx[2]*array_ddlogw_dx[1]))
                                # + dlogw_dx0z*dlogw_dx0y - dlogw_dx0z*dlogw_dx1y - dlogw_dx1z*dlogw_dx0y + dlogw_dx1z*dlogw_dx1y))  
              print('partial--zy end')



              print('partial--zz start')
              partialaazz = tf.split(partial, self.npart,axis=(1))[i]
              partialaazz = tf.reduce_sum(partialaazz, axis=(1))
              partialaazz = tf.split(partialaazz, 3, axis=(1))[2]
              partialaazz = tf.reduce_sum(partialaazz, axis=(1))
              partialaazz = tf.split(partialaazz, self.npart,axis=(1))[i]
              partialaazz = tf.reduce_sum(partialaazz, axis=(1))
              partialaazz = tf.split(partialaazz, 3, axis=(1))[2]
              partialaazz = tf.reduce_sum(partialaazz, axis=(1))
              print(partialaazz)
              
              partialabzz = tf.split(partial, self.npart,axis=(1))[i]
              partialabzz = tf.reduce_sum(partialabzz, axis=(1))
              partialabzz = tf.split(partialabzz, 3, axis=(1))[2]
              partialabzz = tf.reduce_sum(partialabzz, axis=(1))
              partialabzz = tf.split(partialabzz, self.npart,axis=(1))[j]
              partialabzz = tf.reduce_sum(partialabzz, axis=(1))
              partialabzz = tf.split(partialabzz, 3, axis=(1))[2]
              partialabzz = tf.reduce_sum(partialabzz, axis=(1))
              print(partialabzz)

              partialbazz = tf.split(partial, self.npart,axis=(1))[j]
              partialbazz = tf.reduce_sum(partialbazz, axis=(1))
              partialbazz = tf.split(partialbazz, 3, axis=(1))[2]
              partialbazz = tf.reduce_sum(partialbazz, axis=(1))
              partialbazz = tf.split(partialbazz, self.npart,axis=(1))[i]
              partialbazz = tf.reduce_sum(partialbazz, axis=(1))
              partialbazz = tf.split(partialbazz, 3, axis=(1))[2]
              partialbazz = tf.reduce_sum(partialbazz, axis=(1))
              print(partialbazz)

              partialbbzz = tf.split(partial, self.npart,axis=(1))[j]
              partialbbzz = tf.reduce_sum(partialbbzz, axis=(1))
              partialbbzz = tf.split(partialbbzz, 3, axis=(1))[2]
              partialbbzz = tf.reduce_sum(partialbbzz, axis=(1))
              partialbbzz = tf.split(partialbbzz, self.npart,axis=(1))[j]
              partialbbzz = tf.reduce_sum(partialbbzz, axis=(1))
              partialbbzz = tf.split(partialbbzz, 3, axis=(1))[2]
              partialbbzz = tf.reduce_sum(partialbbzz, axis=(1)) 
              print(partialbbzz)    
              term3 = term3 + (array_dwalker[2]*array_dwalker[2]*
                               (partialaazz - partialabzz - partialbazz + partialbbzz
                                + array_ddlogw_dx[2]*array_ddlogw_dx[2]))
                                # + dlogw_dx0z*dlogw_dx0z - dlogw_dx0z*dlogw_dx1z - dlogw_dx1z*dlogw_dx0z + dlogw_dx1z*dlogw_dx1z))
              term3 = term3*(1.0/4.0)
              print('partial--zz end')

              ## From here term2
              term2 = 0.0
              temp11 = 0.0
              for ii in range(3):
                print(ii)
                temp11 = temp11 + array_dwalker[ii]*array_dwalker[ii]


              temp12 = 0.0
              temp12 = temp12 + (  dlogw_dx0x*dlogw_dx0x - dlogw_dx0x*dlogw_dx1x - dlogw_dx1x*dlogw_dx0x + dlogw_dx1x*dlogw_dx1x
                                 + dlogw_dx0y*dlogw_dx0y - dlogw_dx0y*dlogw_dx1y - dlogw_dx1y*dlogw_dx0y + dlogw_dx1y*dlogw_dx1y 
                                 + dlogw_dx0z*dlogw_dx0z - dlogw_dx0z*dlogw_dx1z - dlogw_dx1z*dlogw_dx0z + dlogw_dx1z*dlogw_dx1z)
              # for ii in range(3):
              #   temp12 = temp12 + array_ddlogw_dx[ii]*array_ddlogw_dx[ii]

              #term2 = term2*(1.0/4.0)


              temp13 = 0.0
              # temp13 = temp13 + (
              #       partialaaxx*partialaaxx - partialabxx*partialabxx - partialbaxx*partialbaxx + partialbbxx*partialbbxx 
              #       +partialaayy*partialaayy - partialabyy*partialabyy - partialbayy*partialbayy + partialbbyy*partialbbyy
              #       +partialaazz*partialaazz - partialabzz*partialabzz - partialbazz*partialbazz + partialbbzz*partialbbzz)
              temp13 = temp13 + (
                     partialaaxx - partialabxx - partialbaxx + partialbbxx 
                    +partialaayy - partialabyy - partialbayy + partialbbyy
                    +partialaazz - partialabzz - partialbazz + partialbbzz)              
              term2 = term2 + temp11*temp12 + temp11*temp13
              term2 = term2*(1.0/4.0)              
                



              dl2 = -self.hbarc**2.0 * (-2.0*term1 + term2 - term3)


              
              dwalker = walker0 - walker1
              walker_dnm = dwalker
              walker_dnm = tf.reduce_sum(dwalker,axis=(1))
              print(walker_dnm,'walker_dnm')
              del_r = tf.sqrt(tf.reduce_sum(walker_dnm**2, axis=(1)))
              del_r_2 = tf.reduce_sum(walker_dnm**2, axis=(1))
              Vri0 = (self.V_R0 + self.V_R2*dl2)*tf.exp(-(self.mu_R0**2)*del_r_2) - (self.V_A0 + self.V_A2*dl2)*tf.exp(-(self.mu_A0**2)*del_r_2)

              # Vri0 = (self.V_R2*dl2)*tf.exp(-(self.mu_R0**2)*del_r_2) - (self.V_A2*dl2)*tf.exp(-(self.mu_A0**2)*del_r_2)
              print(Vri0)
              Vri  = Vri0 
              pinteraction = 4.0*self.alpha/del_r*tf.math.erf(0.75*del_r)*self.hbarc 

              Vr = Vr + Vri + pinteraction

          k = M_total* (self.hbaromega**2) / (self.hbarc**2)
          harmonic_pot = tf.cast(0.5, dtype= DEFAULT_TENSOR_TYPE2) * k * sum_R2
          interactiona = Vr + harmonic_pot
        else:
          interactiona = 0


        dwalker = walker0 - walker1
        walker_dnm = dwalker
        walker_dnm = tf.reduce_sum(dwalker,axis=(1))





          ### THREE ALPHA INTERACTION. #########################################

        if self.npart > 2:
          for i in range(self.npart-2):
            for j in range(i+1, self.npart-1):
              for k in range(j+1,self.npart):

                rij = tf.reduce_sum((tf.split(inputs, self.npart, axis=(1))[i] - tf.split(inputs, self.npart, axis=(1))[j]), axis=(1))*self.fm
                rik = tf.reduce_sum((tf.split(inputs, self.npart, axis=(1))[i] - tf.split(inputs, self.npart, axis=(1))[k]), axis=(1))*self.fm
                rjk = tf.reduce_sum((tf.split(inputs, self.npart, axis=(1))[j] - tf.split(inputs, self.npart, axis=(1))[k]), axis=(1))*self.fm

                rij_2 = tf.reduce_sum(rij**2, axis=(1))
                rik_2 = tf.reduce_sum(rik**2, axis=(1))
                rjk_2 = tf.reduce_sum(rjk**2, axis=(1))

                ir1 = rij_2 + rik_2
                ir2 = rij_2 + rjk_2
                ir3 = rik_2 + rjk_2

                interaction21 = self.V03 * tf.exp(-self.lamb*(rij_2+rik_2+rjk_2))
                interaction22 = 0.0#self.V03 * tf.exp(-self.lamb*ir2)
                interaction23 = 0.0#self.V03 * tf.exp(self.lamb*ir3)
                # interaction21 = self.V03 * tf.exp(-self.lamb*ir1)
                # interaction22 = self.V03 * tf.exp(-self.lamb*ir2)
                # interaction23 = self.V03 * tf.exp(-self.lamb*ir3)                
                interaction3 =  (interaction21 + interaction22 + interaction23) + interaction3
        else:
          interaction3 = 0






        
        interaction = interaction + interactiona + interaction3


        return interaction

    @tf.function
    def tot_kinetic_energy(self, *, logw_of_x: tf.Tensor, dlogw_dx: tf.Tensor, d2logw_dx2 : tf.Tensor):

        ke = 0

        for i in range(self.npart):

          dlogw_dxi = tf.split(dlogw_dx, self.npart, axis = (1))[i]
          dlogw_dxi = tf.reduce_sum(dlogw_dxi, axis=(1))*self.fm
          d2logw_dx2i = tf.split(d2logw_dx2, self.npart, axis = (1))[i]
          d2logw_dx2i = tf.reduce_sum(d2logw_dx2i, axis=(1))*self.fm2

          ke_i = -(self.hbarc**2 / (2 * tf.cast((self.mass[i]*self.MeV), DEFAULT_TENSOR_TYPE2))) * (tf.reduce_sum(d2logw_dx2i, axis=(1)) + tf.reduce_sum(dlogw_dxi**2, axis=(1)))
          ke = ke + ke_i

        return ke


    @tf.function
    def compute_energies(self, inputs, logw_of_x, dlogw_dx, d2logw_dx2, w_of_x, dw_dx, d2w_dx2, beforein):

        pe = self.potential_energy(inputs=inputs, Z=4)

        ke_direct = self.tot_kinetic_energy(logw_of_x = logw_of_x,dlogw_dx=dlogw_dx, d2logw_dx2 = d2logw_dx2)

        #interaction = self.interaction_energy(logw_of_x=logw_of_x, inputs=inputs)
        interaction = self.interaction_energy(logw_of_x=logw_of_x, dlogw_dx=dlogw_dx, d2logw_dx2 = d2logw_dx2, inputs=inputs, beforein=beforein)

        return pe, ke_direct, interaction

hamiltonian = HydrogenAtom(sampler)

energy = hamiltonian.energy(ground_state, ground_x)

print(tf.reduce_mean(energy))

def compute_gradients(N_OBSERVATIONS, _sampler, _wavefunction, _hamiltonian):

    @tf.function
    def jacobian(j_x_current, j_wavefunction, _sampler):
        tape = tf.GradientTape()
        with tape:
          tape.watch(j_wavefunction.trainable_variables)
          log_wpsi, w_of_x = j_wavefunction(j_x_current)

        jac = tape.jacobian(log_wpsi, j_wavefunction.trainable_variables)

        jac_shape = [j.shape[1:] for j in jac]
        flat_shape = [[-1, tf.reduce_prod(js)] for js in jac_shape]
        flattened_jacobian = [tf.reshape(j, f) for j, f in zip(jac, flat_shape)]
        flattened_jacobian = tf.concat(flattened_jacobian, axis=-1)

        return flattened_jacobian, flat_shape

    @tf.function
    def compute_O_observables(flattened_jacobian, energy):
        dpsi_i = tf.reduce_mean(flattened_jacobian, axis=0)
        dpsi_i = tf.reshape(dpsi_i, [-1,1])

        dpsi_ij = tf.linalg.matmul(flattened_jacobian, flattened_jacobian, transpose_a = True) / N_WALKERS

        dpsi_i_EL = tf.linalg.matmul(tf.reshape(energy, [1,N_WALKERS]), flattened_jacobian)
        dpsi_i_EL = tf.reshape(dpsi_i_EL, [-1, 1])

        return dpsi_i, dpsi_i_EL, dpsi_ij

    def compute_SR_gradients(crs_energy, csr_dpsi_i, csr_dpsi_i_EL, csr_dpsi_ij):
        
        eps = 0.001
        npt = csr_dpsi_i.shape[0]
    
        gradients = tf.cast(( csr_dpsi_i * crs_energy - csr_dpsi_i_EL ), tf.float64)

        S_ij = tf.cast(csr_dpsi_ij - csr_dpsi_i * tf.transpose(csr_dpsi_i), tf.float64)
        
        i = 0
        while True:
            S_ij_d = S_ij + 2**i * eps * tf.eye(npt, dtype=tf.float64)
            i += 1
            try:
                U_ij = tf.linalg.cholesky(S_ij_d)
                positive_definite = True
            except:
                positive_definite = False
                print(f"Cholesky solve did not find a positive definite matrix on attempt {i}!")
            if positive_definite:
                gradients = tf.linalg.cholesky_solve(U_ij, gradients)
                break
                
        return tf.cast(gradients, tf.float32)

    dpsi_i    = None
    dpsi_i_EL = None
    dpsi_ij   = None
    obs_energy = 0
    
    for i_obs in range(N_OBSERVATIONS):
        kicker = tf.random.normal
        kicker_params = {"mean": 0.0, "stddev" : 0.4}
        acceptance = _sampler.kick(_wavefunction, kicker, kicker_params, nkicks=100)
        x_current  = _sampler.sample()
        energy = hamiltonian.energy(_wavefunction, x_current)
        energy /= N_WALKERS

        flattened_jacobian, flat_shape = jacobian(x_current, _wavefunction, _sampler)

        _dpsi_i, _dpsi_i_EL, _dpsi_ij = compute_O_observables(flattened_jacobian, energy)
        if dpsi_i is None:
            dpsi_i = _dpsi_i
        else:
            dpsi_i += _dpsi_i
            
        if dpsi_i_EL is None:
            dpsi_i_EL = _dpsi_i_EL
        else:
            dpsi_i_EL += _dpsi_i_EL

        if dpsi_ij is None:
            dpsi_ij = _dpsi_ij
        else:
            dpsi_ij += _dpsi_ij

        obs_energy += tf.reduce_sum(energy)
        
    obs_energy /= N_OBSERVATIONS
    dpsi_i     /= N_OBSERVATIONS
    dpsi_i_EL  /= N_OBSERVATIONS
    dpsi_ij    /= N_OBSERVATIONS
    
    
    gradients = compute_SR_gradients(obs_energy, dpsi_i, dpsi_i_EL, dpsi_ij)
    

    # Lastly, reshape the gradients to match the weights:
    running_index = 0
    gradient = []
    for length in flat_shape:
        l = length[-1]
        end_index = running_index + l
        gradient.append(gradients[running_index:end_index])
        running_index += l
    
    shapes = [ p.shape for p in _wavefunction.trainable_variables ]
    gradients = [ tf.reshape(g, s) for g, s in zip(gradient, shapes)]
    return gradients, obs_energy

energy_history = []
steps_history  = []
LEARNING_RATE  = 0.01
npart = sampler.part()
print('particle number :', npart)

"""## Optimization Loop"""

# Define a figure here which we can update along the way:
fig       = plt.figure(figsize=(16,9))
# Create 2x2 sub plots
# gs = gridspec.GridSpec(2, 2)
gs = gridspec.GridSpec(1, 4)
ax_loss   = plt.subplot(gs[0:,0])
ax_denst  = plt.subplot(gs[0:,1], projection="3d")
ax_denst2 = plt.subplot(gs[0:,2], projection="3d")

iteration = 6000
for i in range(iteration):
    
    gradients, energy = compute_gradients(N_OBSERVATIONS, sampler, ground_state, hamiltonian)
    # Scale by the learning rate
    gradients = [LEARNING_RATE * g for g in gradients]
    if energy < 0.0 :
      LEARNING_RATE=0.001
      if energy < -5.0:
        LEARNING_RATE=0.0001
        
    # if energy < -8.0 :
    #   LEARNING_RATE=0.00005

    for i_param in range(len(ground_state.trainable_variables)):
        ground_state.trainable_variables[i_param].assign_add(gradients[i_param])
    print(tf.reduce_mean(energy),i,'/',iteration,  '||learning_rate : ',LEARNING_RATE)        

    
    energy_history.append(energy)
    steps_history.append(i)

    # Here we update the plots.  Show the energy function:
    ax_loss.set_xlim(0, 1.1*i)
    ax_loss.cla()
    ax_loss.plot(steps_history, energy_history, label="Energy")
    ax_loss.grid(True)
    ax_loss.legend(fontsize=25)
    ax_loss.set_ylabel('iteration')

    ax_loss.set_ylabel('eV')

    # Show the location of the walkers:


    view_wolker1 = tf.split(sampler.sample(), npart, axis=(1))[0]
    view_wolker1 = tf.reduce_sum(view_wolker1, axis=(1))
    x1, y1, z1 = tf.split(view_wolker1, 3, axis=1)
    ax_denst.clear()
    ax_denst.set_xlim(-4,4); ax_denst.set_ylim(-4,4); ax_denst.set_zlim(-4,4);
    ax_denst.set_xlabel("X1"); ax_denst.set_ylabel("Y1"); ax_denst.set_zlabel("Z1");
    ax_denst.scatter(x1, y1, z1, linewidth=0.5);


    view_wolker2 = tf.split(sampler.sample(), npart, axis=(1))[1]
    view_wolker2 = tf.reduce_sum(view_wolker2, axis=(1))
    x2, y2, z2 = tf.split(view_wolker2, 3, axis=1)
    ax_denst2.clear()
    ax_denst2.set_xlim(-4,4); ax_denst2.set_ylim(-4,4); ax_denst2.set_zlim(-4,4);
    ax_denst2.set_xlabel("X2"); ax_denst2.set_ylabel("Y2"); ax_denst2.set_zlabel("Z2");
    ax_denst2.scatter(x1, y1, z1, linewidth=0.5);
    ax_denst2.scatter(x2, y2, z2, linewidth=0.5);

    display(fig)
    clear_output(wait = True)
#     plt.pause(0.25)

plt.savefig("./energy-coll.png")
kicker = tf.random.normal
kicker_params = {"mean": 0.0, "stddev" : 0.4}
acceptance = sampler.kick(ground_state, kicker, kicker_params, nkicks=5000)
x = sampler.sample()
energy = hamiltonian.energy(ground_state, x)
print(tf.reduce_mean(energy))

# output.write('average energy : %12.8f %12.8f \n'%(average, std))
output = open('./output.data','w+')
for i in range(len(energy_history)):
  output.write('%6d  %12.8f \n'%( i, energy_history[i]))
output.close()

kicker = tf.random.normal
kicker_params = {"mean": 0.0, "stddev" : 0.4}

acceptance = sampler.kick(ground_state, kicker, kicker_params, nkicks=5000)
x = sampler.sample()
energy = hamiltonian.energy(ground_state, x)
print(tf.reduce_mean(energy))

# print(ground_state.containment) # (If you load my model, this should be 0.011789099)

plt.figure(figsize=(10,10))
plt.rcParams["figure.figsize"] = (10, 10)
check_std_array = []
check_std = []
check_averages = []
check_interval = []
check_average = 0
check_section = 20
for i in range(int(len(energy_history)/check_section)):
  ia = i+1
  for j in range(check_section*i, check_section*ia):
    check_average = check_average + energy_history[j]
    check_std_array.append(energy_history[j])

  check_interval.append(check_section*(ia))
  check_average = check_average/check_section
  check_averages.append(check_average)
  check_std.append(numpy.std(check_std_array))
  check_std_array = []
  check_average = 0

print(len(check_interval), len(check_averages), len(check_std))

check_x = check_interval
check_y = check_averages
check_e = check_std

output = open('./check.data','w+')
for i in range(len(check_y)):
  output.write('%12.8f,%12.8f,%12.8f \n'%(check_x[i], check_y[i], check_std[i]))
output.close()

plt.errorbar(check_x, check_y, check_e, linestyle='None', marker='', label="Energy")
plt.grid(True)
plt.savefig("./before.png")      
#plt.show()

plt.errorbar(check_x, check_y, check_e, linestyle='None', marker='', label="Energy")

plt.grid(True)
plt.savefig("./after.png")       
#plt.show()

choose_x = steps_history
choose_y = energy_history
plt.ylim(check_averages[-1]-check_std[-1]-3, check_averages[-3]+check_std[-3]+3) # 위의 제일 뒤에서 check_section만큼 떨어진 구간별 표춘편차로 y축 확대 위치 지정
plt.xlim(numpy.array(check_interval[-7]), numpy.array(check_interval[-1])) # 위의 제일 뒤에서 check_section으로 잘라 x축 확대 위치 지정
plt.plot(choose_x, choose_y)
#plt.rcParams["figure.figsize"] = (1, 4)
plt.grid(True)
plt.savefig("./effective-range.png")       
#plt.show()

average = 0
average_array = []
for i in range(numpy.array(check_interval[-10]), numpy.array(check_interval[-1])):
  average = average + energy_history[i]
  average_array.append(energy_history[i])
chose_section = numpy.array(check_interval[-1]) - numpy.array(check_interval[-10]) 

average = average / int(chose_section)
std = numpy.std(average_array)
print(average, std)

output = open('./average_energy.txt','w+')
output.write('average energy : %12.8f %12.8f \n'%(average, std))
